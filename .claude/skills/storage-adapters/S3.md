# AWS S3 Adapter Reference

Complete API reference for `@rytass/storages-adapter-s3`.

## Installation

```bash
npm install @rytass/storages @rytass/storages-adapter-s3
```

## Constructor & Configuration

### `StorageS3Service`

```typescript
import { StorageS3Service } from '@rytass/storages-adapter-s3';

const storage = new StorageS3Service(options: StorageS3Options);
```

### `StorageS3Options`

Configuration options for AWS S3 storage adapter.

| Option | Type | Required | Description |
|--------|------|----------|-------------|
| `accessKey` | `string` | **Yes** | AWS access key ID for authentication |
| `secretKey` | `string` | **Yes** | AWS secret access key for authentication |
| `bucket` | `string` | **Yes** | S3 bucket name where files will be stored |
| `region` | `string` | **Yes** | AWS region (e.g., `'ap-northeast-1'`, `'us-east-1'`) |
| `endpoint` | `string` | No | Custom S3 endpoint URL (useful for S3-compatible services) |
| `converters` | `FileConverter<O>[]` | No | Array of file converters to process files before upload |
| `hashAlgorithm` | `'sha1' \| 'sha256'` | No | Hash algorithm for auto-generated filenames (default: `'sha256'`) |

**Example:**

```typescript
const storage = new StorageS3Service({
  accessKey: process.env.AWS_ACCESS_KEY_ID!,
  secretKey: process.env.AWS_SECRET_ACCESS_KEY!,
  bucket: 'my-app-files',
  region: 'ap-northeast-1',
});

// With custom endpoint (for S3-compatible services)
const minioStorage = new StorageS3Service({
  accessKey: 'minio-access-key',
  secretKey: 'minio-secret-key',
  bucket: 'my-bucket',
  region: 'us-east-1',
  endpoint: 'https://minio.example.com',
});
```

## Methods

### `write(file, options?)`

Upload a single file to S3.

**Signature:**
```typescript
write(file: Buffer | Readable, options?: WriteFileOptions): Promise<StorageFile>
```

**Parameters:**

| Parameter | Type | Description |
|-----------|------|-------------|
| `file` | `Buffer \| Readable` | File content as Buffer or Stream |
| `options` | `WriteFileOptions` | Optional upload configuration |
| `options.filename` | `string` | Custom filename (if not provided, auto-generates hash-based name) |
| `options.contentType` | `string` | MIME type (if not provided, auto-detects from file) |

**Returns:** `Promise<StorageFile>` - Object with `key` property containing the file's storage key

**Example:**

```typescript
import { readFileSync, createReadStream } from 'fs';

// Upload Buffer
const buffer = readFileSync('./report.pdf');
const file1 = await storage.write(buffer, {
  filename: 'documents/monthly-report.pdf',
  contentType: 'application/pdf',
});
console.log('File key:', file1.key); // documents/monthly-report.pdf

// Upload Stream with auto-generated filename
const stream = createReadStream('./photo.jpg');
const file2 = await storage.write(stream);
console.log('File key:', file2.key); // a3f2c1b4e5d6...abc123.jpg

// Upload Buffer without custom filename (auto-generates hash-based name)
const buffer2 = Buffer.from('Hello World');
const file3 = await storage.write(buffer2, {
  contentType: 'text/plain',
});
console.log('File key:', file3.key); // 3e25960a79dbc69b...txt
```

### `batchWrite(files)`

Upload multiple files in parallel.

**Signature:**
```typescript
batchWrite(files: InputFile[]): Promise<StorageFile[]>
```

**Parameters:**

| Parameter | Type | Description |
|-----------|------|-------------|
| `files` | `(Buffer \| Readable)[]` | Array of files to upload |

**Returns:** `Promise<StorageFile[]>` - Array of uploaded file objects (filenames auto-generated with hash)

**Example:**

```typescript
const files = [
  readFileSync('./file1.pdf'),
  readFileSync('./file2.jpg'),
  readFileSync('./file3.txt'),
];

// S3 batchWrite does NOT support options array - filenames are auto-generated
const results = await storage.batchWrite(files);

results.forEach((file, index) => {
  console.log(`File ${index + 1} uploaded:`, file.key);
  // Keys will be hash-based, e.g., "a3f2c1b4...abc123.pdf"
});
```

**Note:** To upload files with custom filenames in S3, use `write()` in a loop instead:

```typescript
const files = [
  { buffer: readFileSync('./file1.pdf'), filename: 'docs/file1.pdf' },
  { buffer: readFileSync('./file2.jpg'), filename: 'images/file2.jpg' },
];

const results = await Promise.all(
  files.map(f => storage.write(f.buffer, { filename: f.filename }))
);
```

### `read(key, options?)`

Download a file from S3.

**Signatures:**
```typescript
read(key: string): Promise<Readable>
read(key: string, options: { format: 'buffer' }): Promise<Buffer>
read(key: string, options: { format: 'stream' }): Promise<Readable>
```

**Parameters:**

| Parameter | Type | Description |
|-----------|------|-------------|
| `key` | `string` | File key (path) in S3 bucket |
| `options` | `ReadBufferFileOptions \| ReadStreamFileOptions` | Download format specification |
| `options.format` | `'buffer' \| 'stream'` | Return type: Buffer or Stream |

**Returns:**
- `Promise<Readable>` when `format` is `'stream'` or not specified
- `Promise<Buffer>` when `format` is `'buffer'`

**Example:**

```typescript
// Download as Buffer
const buffer = await storage.read('documents/report.pdf', { format: 'buffer' });
console.log('File size:', buffer.length);

// Download as Stream
const stream = await storage.read('documents/report.pdf', { format: 'stream' });
stream.pipe(createWriteStream('./downloaded-report.pdf'));

// Default: returns Stream
const defaultStream = await storage.read('documents/report.pdf');
defaultStream.pipe(process.stdout);
```

**Throws:** `StorageError` with `ErrorCode.FILE_NOT_FOUND` or `ErrorCode.READ_FILE_ERROR`

### `remove(key)`

Delete a file from S3.

**Signature:**
```typescript
remove(key: string): Promise<void>
```

**Parameters:**

| Parameter | Type | Description |
|-----------|------|-------------|
| `key` | `string` | File key (path) to delete |

**Returns:** `Promise<void>`

**Example:**

```typescript
await storage.remove('documents/old-report.pdf');
console.log('File deleted successfully');
```

**Throws:** `StorageError` with `ErrorCode.REMOVE_FILE_ERROR`

### `isExists(key)`

Check if a file exists in S3.

**Signature:**
```typescript
isExists(key: string): Promise<boolean>
```

**Parameters:**

| Parameter | Type | Description |
|-----------|------|-------------|
| `key` | `string` | File key (path) to check |

**Returns:** `Promise<boolean>` - `true` if file exists, `false` otherwise

**Example:**

```typescript
const exists = await storage.isExists('documents/report.pdf');

if (exists) {
  console.log('File exists');
  const file = await storage.read('documents/report.pdf', { format: 'buffer' });
} else {
  console.log('File not found');
}
```

### `url(key)`

Generate a presigned URL for temporary file access.

**Signature:**
```typescript
url(key: string): Promise<string>
```

**Parameters:**

| Parameter | Type | Description |
|-----------|------|-------------|
| `key` | `string` | File key (path) to generate URL for |

**Returns:** `Promise<string>` - Presigned URL valid for limited time (default expiration set by AWS SDK)

**Example:**

```typescript
const presignedUrl = await storage.url('documents/report.pdf');
console.log('Download URL:', presignedUrl);
// https://my-bucket.s3.ap-northeast-1.amazonaws.com/documents/report.pdf?X-Amz-Algorithm=...

// Share URL with users for temporary access
res.json({ downloadUrl: presignedUrl });
```

**Note:** The presigned URL allows anyone with the URL to download the file without authentication, so share it carefully.

## Types

### `InputFile`

```typescript
type InputFile = Buffer | Readable;
```

Files can be provided as:
- **Buffer**: In-memory file content
- **Readable**: Node.js stream for large files

### `StorageFile`

```typescript
interface StorageFile {
  readonly key: string;
}
```

Result object containing the file's storage key (path).

### `WriteFileOptions`

```typescript
interface WriteFileOptions {
  filename?: string;
  contentType?: string;
}
```

Optional configuration for file uploads:
- `filename`: Custom file path/name in bucket
- `contentType`: MIME type (e.g., `'application/pdf'`, `'image/jpeg'`)

### `ReadBufferFileOptions`

```typescript
interface ReadBufferFileOptions {
  format: 'buffer';
}
```

Specifies download as Buffer.

### `ReadStreamFileOptions`

```typescript
interface ReadStreamFileOptions {
  format: 'stream';
}
```

Specifies download as Stream.

## Error Handling

All methods may throw `StorageError` from `@rytass/storages`:

```typescript
import { StorageError, ErrorCode } from '@rytass/storages';

try {
  await storage.remove('important-file.pdf');
} catch (error) {
  if (error instanceof StorageError) {
    switch (error.code) {
      case ErrorCode.FILE_NOT_FOUND:
        console.error('File does not exist');
        break;
      case ErrorCode.REMOVE_FILE_ERROR:
        console.error('Failed to delete file:', error.message);
        break;
      default:
        console.error('Unexpected error:', error.message);
    }
  }
}
```

## Complete Example

```typescript
import { StorageS3Service } from '@rytass/storages-adapter-s3';
import { StorageError, ErrorCode } from '@rytass/storages';
import { readFileSync, createWriteStream } from 'fs';

async function main() {
  // 1. Initialize S3 storage
  const storage = new StorageS3Service({
    accessKey: process.env.AWS_ACCESS_KEY_ID!,
    secretKey: process.env.AWS_SECRET_ACCESS_KEY!,
    bucket: 'my-application-files',
    region: 'ap-northeast-1',
  });

  try {
    // 2. Upload a file
    const pdfBuffer = readFileSync('./report.pdf');
    const uploadedFile = await storage.write(pdfBuffer, {
      filename: 'reports/2024/monthly-report.pdf',
      contentType: 'application/pdf',
    });
    console.log('File uploaded:', uploadedFile.key);

    // 3. Check if file exists
    const exists = await storage.isExists(uploadedFile.key);
    console.log('File exists:', exists); // true

    // 4. Generate presigned URL
    const downloadUrl = await storage.url(uploadedFile.key);
    console.log('Download URL:', downloadUrl);

    // 5. Download file as Buffer
    const downloadedBuffer = await storage.read(uploadedFile.key, {
      format: 'buffer',
    });
    console.log('Downloaded file size:', downloadedBuffer.length);

    // 6. Download file as Stream
    const downloadedStream = await storage.read(uploadedFile.key, {
      format: 'stream',
    });
    downloadedStream.pipe(createWriteStream('./downloaded-report.pdf'));

    // 7. Upload multiple files (auto-generated hash filenames)
    const files = [
      readFileSync('./file1.txt'),
      readFileSync('./file2.jpg'),
      readFileSync('./file3.json'),
    ];

    const batchResults = await storage.batchWrite(files);

    batchResults.forEach((file) => {
      console.log('Batch uploaded:', file.key);
    });

    // For custom filenames, use write() in a loop:
    const customFiles = [
      { buffer: readFileSync('./file1.txt'), filename: 'texts/file1.txt', contentType: 'text/plain' },
      { buffer: readFileSync('./file2.jpg'), filename: 'images/file2.jpg', contentType: 'image/jpeg' },
    ];
    const customResults = await Promise.all(
      customFiles.map(f => storage.write(f.buffer, { filename: f.filename, contentType: f.contentType }))
    );

    // 8. Delete a file
    await storage.remove('reports/2024/old-report.pdf');
    console.log('Old file deleted');

    // 9. Verify deletion
    const stillExists = await storage.isExists('reports/2024/old-report.pdf');
    console.log('Old file still exists:', stillExists); // false
  } catch (error) {
    if (error instanceof StorageError) {
      console.error('Storage error:', error.code, error.message);
    } else {
      console.error('Unexpected error:', error);
    }
  }
}

main();
```
